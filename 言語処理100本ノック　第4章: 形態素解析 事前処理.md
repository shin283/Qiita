仕事で自然言語処理をやることになったが、全くの素人のため100本ノックで学習する。
Pythonも素人なので、ひとまず解いてみて先人の方のよりイケてるコードを学びたい。
仕事で自然言語処理モデルのBERTを使うため、事前学習モデルとして[京大 黒橋・村脇研究室のBERT日本語Pretrainedモデル](http://nlp.ist.i.kyoto-u.ac.jp/index.php?BERT日本語Pretrainedモデル)を利用する予定。
調べると形態素解析はJuman++を使わないとダメなので、100本ノックでMeCabを使て〜、の部分はJuman++をつかって〜、に読み替えて解く。

実行環境
・MacOS
・[Anaconda](https://www.anaconda.com/products/individual)からのJupyter Notebook
・Python 3.7


# 第4章: 形態素解析 事前処理
> 夏目漱石の小説『吾輩は猫である』の文章（neko.txt）をMeCabを使って形態素解析し，その結果をneko.txt.mecabというファイルに保存せよ．このファイルを用いて，以下の問に対応するプログラムを実装せよ． なお，問題37, 38, 39はmatplotlibもしくはGnuplotを用いるとよい

### データ前処理
ひとまずファイル読み込み

``` python
# ファイル読み込み
# https://note.nkmk.me/python-file-io-open-with/
path = '/Users/shin/Documents/NLP/neko.txt'
with open(path) as f:
    l = f.readlines()
    print(l)
```

結果

```
['一\n', '\n', '\u3000吾輩は猫である。\n', '名前はまだ無い。\n', '\n', '\u3000どこで生れたかとんと見当がつかぬ。\n', '何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。\n', '吾輩はここで始めて人間というものを見た。\n', 'しかもあとで聞くとそれは書生という人間中で一番獰悪な種族であったそうだ。\n', 'この書生というのは時々我々を捕えて煮
```


データの中身を見ると、
・\n
・\u3000
・半角スペース ※後述の形態素解析で処理出来ないことが発覚
といった不要な文字があるので削除する。

``` python
# 改行（\n）、全角空白（\u3000）の削除
# https://qiita.com/tag1216/items/df6c93bdb823dd48af6c

# Pythonで文字列のリスト（配列）の条件を満たす要素を抽出、置換
# https://note.nkmk.me/python-list-str-select-replace/
table = str.maketrans({
    '\n': '',
    '\u3000': '',
    # 半角スペースだと形態素解析でうまくいかなかったため、全角スペースに変換
    # https://qiita.com/trtd56/items/2f62a390eb8fab92e801
    ' ':'　'
})

l_replace = [s.translate(table) for s in l]
l_replace
```

結果

```
['一',
 '',
 '吾輩は猫である。',
 '名前はまだ無い。',
 '',
 'どこで生れたかとんと見当がつかぬ。',
```

上記のように空のリストデータが残るので、データ削除する。

``` python
# 空のlist削除
# https://note.nkmk.me/python-list-clear-pop-remove-del/
l_replace = [s for s in l_replace if s != '']
```

以上で前処理が出来たので、順次問題を解いていく。
